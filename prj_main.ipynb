{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2848137f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a26bb",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c11bf6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T04:03:33.610931Z",
     "start_time": "2023-12-13T04:03:32.411881Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import statement\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Import custom functions\n",
    "from models2 import linreg, logreg, lda, nb, dtl, el_all, el_lin, el_rf\n",
    "\n",
    "# Display all rows\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bdbdfa",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df012f02",
   "metadata": {},
   "source": [
    "## Evaluation metrics for classifiers - evaluate_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ee4c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T04:03:34.494088Z",
     "start_time": "2023-12-13T04:03:34.476016Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_classifier(clf, train_data, test_data, unseen_data):\n",
    "    \n",
    "    # Get the actual/predicted labels for testing and unseen data\n",
    "    y_test, y_test_pred, y_unseen, y_unseen_pred,_ = clf(train_data,test_data,unseen_data)\n",
    "    \n",
    "    # Get metrics for test/unseen data in tuples\n",
    "    accuracy = (accuracy_score(y_test, y_test_pred),accuracy_score(y_unseen, y_unseen_pred))\n",
    "    precision = (precision_score(y_test, y_test_pred, zero_division=1),precision_score(y_unseen, y_unseen_pred,zero_division=1))\n",
    "    recall = (recall_score(y_test, y_test_pred),recall_score(y_unseen, y_unseen_pred))\n",
    "    f1 = (f1_score(y_test, y_test_pred),f1_score(y_unseen, y_unseen_pred))\n",
    "    roc_auc = (roc_auc_score(y_test, y_test_pred),roc_auc_score(y_unseen, y_unseen_pred))\n",
    "\n",
    "    # Return the list of metrics\n",
    "    return [accuracy, precision, recall, f1, roc_auc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652113f",
   "metadata": {},
   "source": [
    "## Get the table of metrics for all classifiers - get_metricTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecae1e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T04:03:35.088002Z",
     "start_time": "2023-12-13T04:03:35.067731Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metricTable(c_list, train_data, test_data, unseen_data):\n",
    "    \n",
    "    # Get the classifier names\n",
    "    c_names = [algo.__name__ for algo in c_list]\n",
    "    \n",
    "    # Create first column as metric and rest should be classifier names\n",
    "    columns = ['metric','dataset'] + c_names\n",
    "    \n",
    "    # Create dataframe to hold metrics table\n",
    "    results = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    # List of metric names and their data\n",
    "    metrics = ['Accuracy %', 'Precision %', 'Recall %', 'F1 %', 'ROC-AUC']\n",
    "    metric_data = []\n",
    "    \n",
    "    # Initialize the dataframe with rows for each metric and dataset\n",
    "    for metric in metrics:\n",
    "        metric_data.append({'metric': metric, 'dataset': 'Test'})\n",
    "        metric_data.append({'metric': metric, 'dataset': 'Unseen'})\n",
    "        metric_data.append({'metric': metric, 'dataset': 'Average'}) \n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    results = pd.DataFrame(metric_data)\n",
    "   \n",
    "    \n",
    "    # Evaluate each classifier and add their metrics to the dataframe\n",
    "    for i, clf in enumerate(c_list):\n",
    "        \n",
    "        print(f\"Calculating metrics for {clf.__name__}\")\n",
    "        \n",
    "        # Get metrics for the current classifier\n",
    "        metrics = evaluate_classifier(clf, train_data, test_data, unseen_data)\n",
    "        \n",
    "    # Write the metrics to the dataframe and calculate averages\n",
    "        for j, metric in enumerate(metrics):\n",
    "            test_metric = metric[0]\n",
    "            unseen_metric = metric[1]\n",
    "            average_metric = (test_metric + unseen_metric) / 2 \n",
    "            \n",
    "            # Round to 1 decimal place if ROC-AUC, rest all 2 for pct% representation\n",
    "            if j == 4:\n",
    "                results.at[3*j, c_names[i]] = round(test_metric,1)\n",
    "                results.at[3*j+1, c_names[i]] = round(unseen_metric,1)\n",
    "                results.at[3*j+2, c_names[i]] = round(average_metric, 1)\n",
    "            else:\n",
    "                results.at[3*j, c_names[i]] = round(test_metric*100,2)\n",
    "                results.at[3*j+1, c_names[i]] = round(unseen_metric*100,2)\n",
    "                results.at[3*j+2, c_names[i]] = round(average_metric*100, 2) \n",
    "\n",
    "    return results\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e032b42",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb669ad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T04:03:36.869554Z",
     "start_time": "2023-12-13T04:03:36.789032Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_dataset = pd.read_csv(\"data/ml_train_data_11-12-23.csv\")\n",
    "test_dataset = pd.read_csv(\"data/ml_test_data_11-12-23.csv\")\n",
    "unseen_dataset = pd.read_csv(\"data/ml_unseen_data_11-12-23.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb0940a",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30d2ff",
   "metadata": {},
   "source": [
    "## Get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960638ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T04:04:23.015301Z",
     "start_time": "2023-12-13T04:03:38.342914Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for linreg\n",
      "Calculating metrics for logreg\n",
      "Calculating metrics for lda\n",
      "Calculating metrics for nb\n",
      "Calculating metrics for dtl\n",
      "Calculating metrics for el_all\n",
      "Ensembling linreg\n",
      "Ensembling logreg\n",
      "Ensembling lda\n",
      "Ensembling nb\n",
      "Ensembling dtl\n",
      "Calculating metrics for el_lin\n",
      "Ensembling linreg\n",
      "Ensembling lda\n",
      "Ensembling dtl\n",
      "Calculating metrics for el_rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farzanmirza/Desktop/Drive/Drexel/Current/CS613/Prj/models2.py:309: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.exp(-1*((X_i-mean_i)**2)/2*std_i**2)/(std_i*math.sqrt(2*math.pi))\n",
      "/Users/farzanmirza/Desktop/Drive/Drexel/Current/CS613/Prj/models2.py:275: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior_per_observation[key] = posterior_per_observation[key] / result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>dataset</th>\n",
       "      <th>linreg</th>\n",
       "      <th>logreg</th>\n",
       "      <th>lda</th>\n",
       "      <th>nb</th>\n",
       "      <th>dtl</th>\n",
       "      <th>el_all</th>\n",
       "      <th>el_lin</th>\n",
       "      <th>el_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy %</td>\n",
       "      <td>Test</td>\n",
       "      <td>66.35</td>\n",
       "      <td>50.14</td>\n",
       "      <td>65.56</td>\n",
       "      <td>54.75</td>\n",
       "      <td>49.86</td>\n",
       "      <td>54.88</td>\n",
       "      <td>66.29</td>\n",
       "      <td>50.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy %</td>\n",
       "      <td>Unseen</td>\n",
       "      <td>65.80</td>\n",
       "      <td>50.24</td>\n",
       "      <td>65.77</td>\n",
       "      <td>59.15</td>\n",
       "      <td>49.75</td>\n",
       "      <td>59.10</td>\n",
       "      <td>65.17</td>\n",
       "      <td>50.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accuracy %</td>\n",
       "      <td>Average</td>\n",
       "      <td>66.08</td>\n",
       "      <td>50.19</td>\n",
       "      <td>65.66</td>\n",
       "      <td>56.95</td>\n",
       "      <td>49.81</td>\n",
       "      <td>56.99</td>\n",
       "      <td>65.73</td>\n",
       "      <td>50.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precision %</td>\n",
       "      <td>Test</td>\n",
       "      <td>64.99</td>\n",
       "      <td>50.00</td>\n",
       "      <td>63.88</td>\n",
       "      <td>52.55</td>\n",
       "      <td>49.86</td>\n",
       "      <td>52.57</td>\n",
       "      <td>62.31</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision %</td>\n",
       "      <td>Unseen</td>\n",
       "      <td>63.15</td>\n",
       "      <td>50.00</td>\n",
       "      <td>63.24</td>\n",
       "      <td>55.81</td>\n",
       "      <td>49.75</td>\n",
       "      <td>55.37</td>\n",
       "      <td>61.16</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Precision %</td>\n",
       "      <td>Average</td>\n",
       "      <td>64.07</td>\n",
       "      <td>50.00</td>\n",
       "      <td>63.56</td>\n",
       "      <td>54.18</td>\n",
       "      <td>49.81</td>\n",
       "      <td>53.97</td>\n",
       "      <td>61.74</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Recall %</td>\n",
       "      <td>Test</td>\n",
       "      <td>70.49</td>\n",
       "      <td>99.93</td>\n",
       "      <td>71.16</td>\n",
       "      <td>95.12</td>\n",
       "      <td>100.00</td>\n",
       "      <td>97.16</td>\n",
       "      <td>82.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Recall %</td>\n",
       "      <td>Unseen</td>\n",
       "      <td>75.05</td>\n",
       "      <td>99.37</td>\n",
       "      <td>74.51</td>\n",
       "      <td>85.93</td>\n",
       "      <td>100.00</td>\n",
       "      <td>91.69</td>\n",
       "      <td>82.19</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recall %</td>\n",
       "      <td>Average</td>\n",
       "      <td>72.77</td>\n",
       "      <td>99.65</td>\n",
       "      <td>72.83</td>\n",
       "      <td>90.53</td>\n",
       "      <td>100.00</td>\n",
       "      <td>94.43</td>\n",
       "      <td>82.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F1 %</td>\n",
       "      <td>Test</td>\n",
       "      <td>67.63</td>\n",
       "      <td>66.65</td>\n",
       "      <td>67.32</td>\n",
       "      <td>67.70</td>\n",
       "      <td>66.54</td>\n",
       "      <td>68.22</td>\n",
       "      <td>70.81</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F1 %</td>\n",
       "      <td>Unseen</td>\n",
       "      <td>68.59</td>\n",
       "      <td>66.52</td>\n",
       "      <td>68.41</td>\n",
       "      <td>67.67</td>\n",
       "      <td>66.45</td>\n",
       "      <td>69.05</td>\n",
       "      <td>70.14</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>F1 %</td>\n",
       "      <td>Average</td>\n",
       "      <td>68.11</td>\n",
       "      <td>66.59</td>\n",
       "      <td>67.87</td>\n",
       "      <td>67.69</td>\n",
       "      <td>66.49</td>\n",
       "      <td>68.64</td>\n",
       "      <td>70.47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>Unseen</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ROC-AUC</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         metric  dataset  linreg  logreg    lda     nb     dtl  el_all  \\\n",
       "0    Accuracy %     Test   66.35   50.14  65.56  54.75   49.86   54.88   \n",
       "1    Accuracy %   Unseen   65.80   50.24  65.77  59.15   49.75   59.10   \n",
       "2    Accuracy %  Average   66.08   50.19  65.66  56.95   49.81   56.99   \n",
       "3   Precision %     Test   64.99   50.00  63.88  52.55   49.86   52.57   \n",
       "4   Precision %   Unseen   63.15   50.00  63.24  55.81   49.75   55.37   \n",
       "5   Precision %  Average   64.07   50.00  63.56  54.18   49.81   53.97   \n",
       "6      Recall %     Test   70.49   99.93  71.16  95.12  100.00   97.16   \n",
       "7      Recall %   Unseen   75.05   99.37  74.51  85.93  100.00   91.69   \n",
       "8      Recall %  Average   72.77   99.65  72.83  90.53  100.00   94.43   \n",
       "9          F1 %     Test   67.63   66.65  67.32  67.70   66.54   68.22   \n",
       "10         F1 %   Unseen   68.59   66.52  68.41  67.67   66.45   69.05   \n",
       "11         F1 %  Average   68.11   66.59  67.87  67.69   66.49   68.64   \n",
       "12      ROC-AUC     Test    0.70    0.50   0.70   0.50    0.50    0.50   \n",
       "13      ROC-AUC   Unseen    0.70    0.50   0.70   0.60    0.50    0.60   \n",
       "14      ROC-AUC  Average    0.70    0.50   0.70   0.60    0.50    0.60   \n",
       "\n",
       "    el_lin   el_rf  \n",
       "0    66.29   50.14  \n",
       "1    65.17   50.25  \n",
       "2    65.73   50.19  \n",
       "3    62.31  100.00  \n",
       "4    61.16  100.00  \n",
       "5    61.74  100.00  \n",
       "6    82.00    0.00  \n",
       "7    82.19    0.00  \n",
       "8    82.10    0.00  \n",
       "9    70.81    0.00  \n",
       "10   70.14    0.00  \n",
       "11   70.47    0.00  \n",
       "12    0.70    0.50  \n",
       "13    0.70    0.50  \n",
       "14    0.70    0.50  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define algorithm list\n",
    "algos = [linreg,logreg,lda,nb, dtl, el_all, el_lin, el_rf]\n",
    "\n",
    "m_table = get_metricTable(algos, train_dataset, test_dataset, unseen_dataset)\n",
    "\n",
    "m_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e824c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507da23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291630d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee197f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29a12ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c29d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.993px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
