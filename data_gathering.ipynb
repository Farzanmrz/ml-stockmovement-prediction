{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ebd09dd",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bd918d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a154051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:54:21.817718Z",
     "start_time": "2023-12-13T01:54:21.805864Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "# Display all rows\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e609f7e",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36fcb1c",
   "metadata": {},
   "source": [
    "## get_random_startDates(n=40)\n",
    "\n",
    "**Purpose:** This function generates a sequence of unique and random start dates. These dates fall within a specified range, starting from 59 days prior to the current date and ending yesterday\n",
    "<br>\n",
    "**Usage:** The primary application of these dates is to define the starting points for 1-day windows, each extending to the following day. This approach is particularly suited for acquiring stock data at 5-minute intervals within these 24-hour periods\n",
    "<br>\n",
    "**Features:** Avoids thanksgiving holidays and start dates that will create 1-day interval with a weekend, picks 35 dates since we will take 35 windows for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "752c2b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:54:26.037882Z",
     "start_time": "2023-12-13T01:54:26.023584Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_startDates(n=35):\n",
    "\n",
    "    # Set range from 59 days before today till yesterday\n",
    "    max_end_date = datetime.now().date() - timedelta(days=1)\n",
    "    min_start_date = max_end_date - timedelta(days=56)\n",
    "\n",
    "    # Avoid thanksgiving holiday\n",
    "    excluded_dates = {\n",
    "        datetime(2023, 11, 23).date(),\n",
    "        datetime(2023, 11, 24).date()\n",
    "    }\n",
    "\n",
    "    # Generate a list of all valid dates\n",
    "    valid_dates = [\n",
    "        min_start_date + timedelta(days=i)\n",
    "        for i in range((max_end_date - min_start_date).days + 1)\n",
    "        if (min_start_date + timedelta(days=i) not in excluded_dates) and\n",
    "        (min_start_date + timedelta(days=i)).weekday() < 5\n",
    "    ]\n",
    "\n",
    "    # Randomly select n dates from the list of valid dates\n",
    "    if len(valid_dates) < n:\n",
    "        raise ValueError(\n",
    "            \"Not enough valid dates available to meet the requested count.\")\n",
    "\n",
    "    start_dates = random.sample(valid_dates, n)\n",
    "    start_dates = [date.strftime(\"%Y-%m-%d\") for date in start_dates]\n",
    "\n",
    "    return start_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21580bac",
   "metadata": {},
   "source": [
    "## process_data(data, ticker, start_date, end_date, window_id)\n",
    "\n",
    "**Purpose:** Perform basic data preprocessing to represent information like we want to see it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca522891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:54:26.878058Z",
     "start_time": "2023-12-13T01:54:26.863772Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(data, ticker, start_date, end_date, window_id):\n",
    "\n",
    "    # Rename upper case columns we are keeping\n",
    "    data.rename(columns={ 'Open': 'open','Volume': 'volume' },inplace=True)\n",
    "\n",
    "    # Create new columns for better representation\n",
    "    data['stock'] = ticker\n",
    "    data['start_date'] = f\"{start_date}\"\n",
    "    data['window_ID'] = window_id\n",
    "    data['timestep'] = range(1, len(data) + 1)\n",
    "    data['volatility'] = data['open'] - data['Low'] \n",
    "    \n",
    "    # Create target column\n",
    "    # Shift the Close price to the previous row to compare it with the current open price\n",
    "    data['target'] = (data['Close'].shift(-1) > data['open']).astype(int)\n",
    "\n",
    "\n",
    "    # Rearrange columns to ensure consistent dataframe structure\n",
    "    columns_order = [\n",
    "        'stock', 'start_date', 'window_ID', 'timestep', 'open', 'volatility',\n",
    "        'volume', 'target'\n",
    "    ]\n",
    "    return data[columns_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc43c4",
   "metadata": {},
   "source": [
    "## shuffle_by_window(df)\n",
    "**Purpose:** Shuffle the time-series interval for given df as per unique window_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "758fb15a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:54:27.532089Z",
     "start_time": "2023-12-13T01:54:27.525947Z"
    }
   },
   "outputs": [],
   "source": [
    "def shuffle_by_window(df):\n",
    "    \n",
    "    # Get unique window_IDs\n",
    "    window_ids = df['window_ID'].unique()\n",
    "    \n",
    "    # Shuffle the list of window_IDs\n",
    "    np.random.shuffle(window_ids)\n",
    "        \n",
    "    # Concatenate all dataframes at once\n",
    "    shuffled_df = pd.concat([df[df['window_ID'] == window_id] for window_id in window_ids], ignore_index=True)\n",
    "    \n",
    "    # Return the shuffled DataFrame\n",
    "    return shuffled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8874c2",
   "metadata": {},
   "source": [
    "## normalize_features(df, fts)\n",
    "**Purpose:** Normalize the features given for the df provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63e6ecf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:54:28.435155Z",
     "start_time": "2023-12-13T01:54:28.420376Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_features(df, fts):\n",
    "    sc = StandardScaler()\n",
    "    df[fts] = sc.fit_transform(df[fts])\n",
    "    return df, sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9b98b",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339898a",
   "metadata": {},
   "source": [
    "## Acquire Data\n",
    "\n",
    "1. Apple - Highest Volume 50m approx - Technology\n",
    "2. Delta Airlines - Above Average Volume 10m approx - Industrial\n",
    "3. Capital One - Average Volume 3m approx - Finance\n",
    "4. CVS - Medium Volume 1m approx - Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "167fa5c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:55:38.054427Z",
     "start_time": "2023-12-13T01:54:29.322057Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PKG\n",
      "GOOGL\n",
      "ARE\n",
      "MHK\n",
      "FFIV\n",
      "C\n",
      "MA\n",
      "BSX\n",
      "COF\n",
      "BAX\n",
      "RSG\n",
      "TSLA\n",
      "IRM\n",
      "KO\n",
      "NEM\n",
      "VZ\n",
      "MRK\n",
      "PSX\n",
      "ATO\n",
      "CF\n",
      "SPG\n",
      "MTCH\n",
      "COP\n",
      "POOL\n",
      "MS\n",
      "DOW\n",
      "RMD\n",
      "MO\n",
      "PYPL\n",
      "NRG\n",
      "DAL\n",
      "SNPS\n",
      "XEL\n",
      "KIM\n",
      "FMC\n",
      "GPN\n",
      "LNT\n",
      "AAPL\n",
      "HSY\n",
      "MCD\n",
      "CLX\n",
      "NI\n",
      "DG\n",
      "EQT\n",
      "CSX\n",
      "DIS\n",
      "NFLX\n",
      "IFF\n",
      "AMZN\n",
      "KMI\n",
      "HST\n",
      "MSFT\n",
      "PCG\n",
      "EQIX\n",
      "PWR\n",
      "ZBRA\n",
      "ACN\n",
      "META\n",
      "HAL\n",
      "WAB\n",
      "CVS\n",
      "SNA\n",
      "CVX\n",
      "GIS\n",
      "LLY\n",
      "NKE\n"
     ]
    }
   ],
   "source": [
    "# Stocks used for training and testing the models\n",
    "train_test_stocks = ['DIS','MTCH',\n",
    "                     'TSLA','MHK',\n",
    "                     'KO','GIS',\n",
    "                     'EQT','KMI', \n",
    "                     'COF', 'PYPL',\n",
    "                     'CVS', 'BSX',\n",
    "                     'DAL','CSX',\n",
    "                     'AAPL','FFIV',\n",
    "                     'FMC','DOW',\n",
    "                     'SPG','IRM',\n",
    "                     'NI','XEL']\n",
    "\n",
    "# Other unseen stocks to check model generalizability\n",
    "unseen_stocks = ['NFLX','META','VZ','GOOGL',\n",
    "                 'MCD','AMZN','NKE','POOL',\n",
    "                 'DG','CLX','HSY','MO',\n",
    "                 'COP','CVX','HAL','PSX',\n",
    "                 'MS','MA','GPN','C',\n",
    "                 'RMD','MRK','LLY','BAX',\n",
    "                 'RSG','PWR','SNA','WAB',\n",
    "                 'ZBRA','SNPS','ACN','MSFT',\n",
    "                 'PKG','NEM','IFF','CF',\n",
    "                'ARE','EQIX','HST','KIM',\n",
    "                 'NRG','PCG','ATO','LNT']\n",
    "\n",
    "# List of all stocks and shuffle them\n",
    "stocks = train_test_stocks + unseen_stocks\n",
    "random.shuffle(stocks)\n",
    "\n",
    "# DataFrame to hold all data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Window ID counter\n",
    "window_id = 1\n",
    "\n",
    "# Download and process the data for each stock and each interval\n",
    "for stock in stocks:   \n",
    "    \n",
    "    # Print the stock being processed\n",
    "    print(stock)\n",
    "    \n",
    "    # Take 35 random days for training stocks and 5 for rest\n",
    "    days = 35 if stock in train_test_stocks else 5\n",
    "    \n",
    "    # Generate unique random start dates\n",
    "    random_start_dates = get_random_startDates(n = days)\n",
    "    \n",
    "    # Loop through each data\n",
    "    for start in random_start_dates:\n",
    "\n",
    "        # Get end date for interval\n",
    "        end = (datetime.strptime(start, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "        # Download data for interval\n",
    "        data = yf.download(tickers=stock, start=start, end=end, interval='5m',progress = False)\n",
    "        \n",
    "        # Process it to match our formatting\n",
    "        processed_data = process_data(data, stock, start, end, window_id)\n",
    "        \n",
    "        # Add to the df holding all data\n",
    "        all_data = pd.concat([all_data, processed_data], ignore_index=True)\n",
    "\n",
    "        # Increment window ID\n",
    "        window_id += 1  \n",
    "\n",
    "\n",
    "\n",
    "# Drop the last row of each window where the shifted Close price would be NaN\n",
    "all_data = all_data.groupby('window_ID').apply(lambda group: group.iloc[:-1]).reset_index(drop=True)\n",
    "\n",
    "# Write readable all_data to CSV\n",
    "all_data.to_csv(f\"data/rd_all_data_{datetime.now().strftime('%d-%m-%y')}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84a625",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Split train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b74d174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:55:41.941396Z",
     "start_time": "2023-12-13T01:55:40.962113Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>start_date</th>\n",
       "      <th>window_ID</th>\n",
       "      <th>timestep</th>\n",
       "      <th>open</th>\n",
       "      <th>volatility</th>\n",
       "      <th>volume</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIS</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>770</td>\n",
       "      <td>1</td>\n",
       "      <td>80.690002</td>\n",
       "      <td>0.279999</td>\n",
       "      <td>221818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIS</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>770</td>\n",
       "      <td>2</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>0.080002</td>\n",
       "      <td>132538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIS</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>770</td>\n",
       "      <td>3</td>\n",
       "      <td>80.430000</td>\n",
       "      <td>0.090004</td>\n",
       "      <td>78192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIS</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>770</td>\n",
       "      <td>4</td>\n",
       "      <td>80.519997</td>\n",
       "      <td>0.169998</td>\n",
       "      <td>102693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIS</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>770</td>\n",
       "      <td>5</td>\n",
       "      <td>80.419998</td>\n",
       "      <td>0.089996</td>\n",
       "      <td>99674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock  start_date  window_ID  timestep       open  volatility  volume  \\\n",
       "0   DIS  2023-10-31        770         1  80.690002    0.279999  221818   \n",
       "1   DIS  2023-10-31        770         2  80.500000    0.080002  132538   \n",
       "2   DIS  2023-10-31        770         3  80.430000    0.090004   78192   \n",
       "3   DIS  2023-10-31        770         4  80.519997    0.169998  102693   \n",
       "4   DIS  2023-10-31        770         5  80.419998    0.089996   99674   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       1  \n",
       "2       0  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate dataframes to store training,testing and unseen data\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "unseen_data = pd.DataFrame()\n",
    "\n",
    "# For each stock in train_test_stocks, the data goes to train_data or test_data based on the window_ID\n",
    "for stock in train_test_stocks:\n",
    "    stock_windows = all_data[all_data['stock'] == stock]['window_ID'].unique()\n",
    "    stock_train = all_data[all_data['window_ID'].isin(stock_windows[:30])]\n",
    "    stock_test = all_data[all_data['window_ID'].isin(stock_windows[30:35])]\n",
    "\n",
    "    train_data = pd.concat([train_data, stock_train], ignore_index=True)\n",
    "    test_data = pd.concat([test_data, stock_test], ignore_index=True)\n",
    "\n",
    "    \n",
    "# For each stock in unseen_stocks, the data goes to unseen_data\n",
    "for stock in unseen_stocks:\n",
    "    stock_unseen = all_data[all_data['stock'] == stock]\n",
    "    unseen_data = pd.concat([unseen_data, stock_unseen], ignore_index=True)\n",
    "    \n",
    "    \n",
    "# Shuffle train_data,test_data,unseen_data by window_ID\n",
    "train_data = shuffle_by_window(train_data)\n",
    "test_data = shuffle_by_window(test_data)\n",
    "unseen_data = shuffle_by_window(unseen_data)\n",
    "\n",
    "# Write readable train, test, unseen data to CSV before normalizing and dropping unnecessary columns\n",
    "train_data.to_csv(f\"data/rd_train_data_{datetime.now().strftime('%d-%m-%y')}.csv\", index=False)\n",
    "test_data.to_csv(f\"data/rd_test_data_{datetime.now().strftime('%d-%m-%y')}.csv\", index=False)\n",
    "unseen_data.to_csv(f\"data/rd_unseen_data_{datetime.now().strftime('%d-%m-%y')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52e4ca5",
   "metadata": {},
   "source": [
    "## Normalize and Drop unrequired columns for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cf94153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:56:57.115221Z",
     "start_time": "2023-12-13T01:56:56.712151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_ID</th>\n",
       "      <th>timestep</th>\n",
       "      <th>open</th>\n",
       "      <th>volatility</th>\n",
       "      <th>volume</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>770</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089041</td>\n",
       "      <td>1.200881</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>770</td>\n",
       "      <td>2</td>\n",
       "      <td>0.085411</td>\n",
       "      <td>-0.032389</td>\n",
       "      <td>-0.051593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770</td>\n",
       "      <td>3</td>\n",
       "      <td>0.084073</td>\n",
       "      <td>0.029289</td>\n",
       "      <td>-0.186662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>770</td>\n",
       "      <td>4</td>\n",
       "      <td>0.085793</td>\n",
       "      <td>0.522569</td>\n",
       "      <td>-0.125768</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>770</td>\n",
       "      <td>5</td>\n",
       "      <td>0.083882</td>\n",
       "      <td>0.029242</td>\n",
       "      <td>-0.133271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_ID  timestep      open  volatility    volume  target\n",
       "0        770         1  0.089041    1.200881  0.170300       0\n",
       "1        770         2  0.085411   -0.032389 -0.051593       1\n",
       "2        770         3  0.084073    0.029289 -0.186662       0\n",
       "3        770         4  0.085793    0.522569 -0.125768       1\n",
       "4        770         5  0.083882    0.029242 -0.133271       1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define fts to be normalized\n",
    "fts = ['open', 'volatility', 'volume']\n",
    "\n",
    "# Normalize features in training data\n",
    "train_data, sc = normalize_features(train_data, fts)\n",
    "\n",
    "# Apply the same transformation to the test,unseen data\n",
    "test_data[fts] = sc.transform(test_data[fts])\n",
    "unseen_data[fts] = sc.transform(unseen_data[fts])\n",
    "\n",
    "# Drop columns stock, start_date since window_ID sufficient\n",
    "train_data = train_data.iloc[:, 2:]\n",
    "test_data = test_data.iloc[:, 2:]\n",
    "unseen_data = unseen_data.iloc[:, 2:]\n",
    "\n",
    "# Write train,test data to be actually used in ML to CSV\n",
    "train_data.to_csv(f\"data/ml_train_data_{datetime.now().strftime('%d-%m-%y')}.csv\", index=False)\n",
    "test_data.to_csv(f\"data/ml_test_data_{datetime.now().strftime('%d-%m-%y')}.csv\", index=False)\n",
    "unseen_data.to_csv(f\"data/ml_unseen_data_{datetime.now().strftime('%d-%m-%y')}.csv\", index=False)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c318cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:45:43.857127Z",
     "start_time": "2023-12-13T01:45:43.551367Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = yf.download(tickers=['AAPL','AMZN'], start='2023-10-14', end='2023-12-11', interval='5m',progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de8da649",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:46:15.537174Z",
     "start_time": "2023-12-13T01:46:15.510097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Adj Close</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Close</th>\n",
       "      <th colspan=\"2\" halign=\"left\">High</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Low</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Open</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-10-16 09:30:00-04:00</th>\n",
       "      <td>178.129898</td>\n",
       "      <td>130.759995</td>\n",
       "      <td>178.129898</td>\n",
       "      <td>130.759995</td>\n",
       "      <td>178.179993</td>\n",
       "      <td>131.070007</td>\n",
       "      <td>176.509995</td>\n",
       "      <td>130.425003</td>\n",
       "      <td>176.750000</td>\n",
       "      <td>130.690002</td>\n",
       "      <td>4407466</td>\n",
       "      <td>1974972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-16 09:35:00-04:00</th>\n",
       "      <td>177.869904</td>\n",
       "      <td>131.160004</td>\n",
       "      <td>177.869904</td>\n",
       "      <td>131.160004</td>\n",
       "      <td>178.360001</td>\n",
       "      <td>131.440002</td>\n",
       "      <td>177.809998</td>\n",
       "      <td>130.750000</td>\n",
       "      <td>178.119995</td>\n",
       "      <td>130.835007</td>\n",
       "      <td>1454933</td>\n",
       "      <td>1003305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-16 09:40:00-04:00</th>\n",
       "      <td>177.300003</td>\n",
       "      <td>131.072693</td>\n",
       "      <td>177.300003</td>\n",
       "      <td>131.072693</td>\n",
       "      <td>178.322495</td>\n",
       "      <td>131.630005</td>\n",
       "      <td>177.277496</td>\n",
       "      <td>130.970001</td>\n",
       "      <td>177.869995</td>\n",
       "      <td>131.172607</td>\n",
       "      <td>1141014</td>\n",
       "      <td>837142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-16 09:45:00-04:00</th>\n",
       "      <td>177.110001</td>\n",
       "      <td>131.380005</td>\n",
       "      <td>177.110001</td>\n",
       "      <td>131.380005</td>\n",
       "      <td>177.509995</td>\n",
       "      <td>131.719894</td>\n",
       "      <td>177.070007</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>177.320007</td>\n",
       "      <td>131.085007</td>\n",
       "      <td>882999</td>\n",
       "      <td>728300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-16 09:50:00-04:00</th>\n",
       "      <td>177.009995</td>\n",
       "      <td>131.929993</td>\n",
       "      <td>177.009995</td>\n",
       "      <td>131.929993</td>\n",
       "      <td>177.429993</td>\n",
       "      <td>131.970001</td>\n",
       "      <td>176.930099</td>\n",
       "      <td>131.384995</td>\n",
       "      <td>177.119995</td>\n",
       "      <td>131.389999</td>\n",
       "      <td>774887</td>\n",
       "      <td>746733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Adj Close                   Close              \\\n",
       "                                 AAPL        AMZN        AAPL        AMZN   \n",
       "Datetime                                                                    \n",
       "2023-10-16 09:30:00-04:00  178.129898  130.759995  178.129898  130.759995   \n",
       "2023-10-16 09:35:00-04:00  177.869904  131.160004  177.869904  131.160004   \n",
       "2023-10-16 09:40:00-04:00  177.300003  131.072693  177.300003  131.072693   \n",
       "2023-10-16 09:45:00-04:00  177.110001  131.380005  177.110001  131.380005   \n",
       "2023-10-16 09:50:00-04:00  177.009995  131.929993  177.009995  131.929993   \n",
       "\n",
       "                                 High                     Low              \\\n",
       "                                 AAPL        AMZN        AAPL        AMZN   \n",
       "Datetime                                                                    \n",
       "2023-10-16 09:30:00-04:00  178.179993  131.070007  176.509995  130.425003   \n",
       "2023-10-16 09:35:00-04:00  178.360001  131.440002  177.809998  130.750000   \n",
       "2023-10-16 09:40:00-04:00  178.322495  131.630005  177.277496  130.970001   \n",
       "2023-10-16 09:45:00-04:00  177.509995  131.719894  177.070007  131.000000   \n",
       "2023-10-16 09:50:00-04:00  177.429993  131.970001  176.930099  131.384995   \n",
       "\n",
       "                                 Open               Volume           \n",
       "                                 AAPL        AMZN     AAPL     AMZN  \n",
       "Datetime                                                             \n",
       "2023-10-16 09:30:00-04:00  176.750000  130.690002  4407466  1974972  \n",
       "2023-10-16 09:35:00-04:00  178.119995  130.835007  1454933  1003305  \n",
       "2023-10-16 09:40:00-04:00  177.869995  131.172607  1141014   837142  \n",
       "2023-10-16 09:45:00-04:00  177.320007  131.085007   882999   728300  \n",
       "2023-10-16 09:50:00-04:00  177.119995  131.389999   774887   746733  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15096df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "345.59px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
